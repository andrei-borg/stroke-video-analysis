{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import packages'''\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import csv\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facialispares 0 - Andrei - 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Det går inte att hitta sökvägen: 'c:\\\\Users\\\\oskar\\\\OneDrive\\\\Dokument\\\\repo\\\\kandidat\\\\stroke-video-analysistestdata\\\\test\\\\Facialispares 0 - Andrei - 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43364\\549955248.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr''\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'testdata\\\\test\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'testdata\\\\test\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Det går inte att hitta sökvägen: 'c:\\\\Users\\\\oskar\\\\OneDrive\\\\Dokument\\\\repo\\\\kandidat\\\\stroke-video-analysistestdata\\\\test\\\\Facialispares 0 - Andrei - 1'"
     ]
    }
   ],
   "source": [
    "\"hog for feature extraction\"\n",
    "hog_faces = []\n",
    "target = []\n",
    "dir = os.getcwd()\n",
    "for folder in os.listdir(r''+dir + '\\\\testdata\\\\test' ):\n",
    "    print(folder)\n",
    "    i = 0\n",
    "    for face in os.listdir(r''+dir + '\\\\testdata\\\\test\\\\' + folder):\n",
    "        i +=1\n",
    "        image = cv2.imread(r'' + dir + 'testdata\\\\test\\\\' + folder + \"\\\\\" + face)\n",
    "        img = cv2.resize(image,(380,380))\n",
    "        \n",
    "        fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8),cells_per_block = (2, 2), visualize=True, multichannel=True)\n",
    "        hog_faces.append(hog_image)\n",
    "        \n",
    "    print(str(i)+\" Faces\")\n",
    "print(\"Done processing...\")\n",
    "\n",
    "#import labels for faces\n",
    "for file in os.listdir(dir + 'testdata\\testlabel'):\n",
    "    file = open(dir + 'testdata\\testlabel\\\\' + file,\"r\")\n",
    "    t = [list(map(int,rec)) for rec in csv.reader(file, delimiter=',')]\n",
    "   \n",
    "    target += t[0]\n",
    "    file.close()\n",
    "    \n",
    "print(\"targets leangth: \" + str(len(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create a dataframe'''\n",
    "face_data = []\n",
    "\n",
    "for face in faces:\n",
    "    f = face.ravel()\n",
    "    face_data.append(f)\n",
    "    \n",
    "print(len(face_data))\n",
    "\n",
    "df = { 'faces': faces,\n",
    "      'target':target,\n",
    "      'data': face_data \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df) \n",
    "print(str(len(faces)) + \" Faces in dataframe\")\n",
    "print(str(len(face_data[0])) + \" Features in a face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"create a training and test set\"\n",
    "\n",
    "h,w = df.faces[0].shape\n",
    "n_samples, n_labels = df.shape\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = df.data.values.tolist()\n",
    "y = df.target\n",
    "n_features = len(X[1])\n",
    "labels =[\"No stroke\",\"Stroke\"]\n",
    "n_classes = len(labels)\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[:2000], y[:2000], test_size=0.25, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"NN model for classification\"\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Fit model to data\"\n",
    "\n",
    "model.compile(optimizer='adam', loss= tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "result = model.fit(X_train, y_train, epochs = 20, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9074b95f083ecba89b9282f7f5e9c53e7d7ab2703d1f890251fa880ef741439"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
